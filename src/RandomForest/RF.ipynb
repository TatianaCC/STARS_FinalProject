{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coherencia de clusters\n",
    "\n",
    "Tras haber descubierto las posibles estructuras en nuestro conjunto de datos, vamos a pasar por un modelo de clasificaci√≥n supervisada para comprobar la coherencia de los clusters encontrados. Nos decantamos por un Random Forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from pickle import dump, load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../Samples/Clean/Testing/HDBSCAN/X_data_with_y_predict_Q.csv')\n",
    "y_hdbscan = df['cluster_hdbscan']\n",
    "x_full = df.drop(columns=['cluster_hdbscan']).copy(deep=True)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_full, y_hdbscan, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([109,  -1, 107, 105, 103,  61,  65,  47,  49,  39,  79,  50,  78,\n",
       "        56,  98,  25,  12,  33,  42,  74,  87,  41,  93,  90,  40,  64,\n",
       "        45,  26,  38,  77,  18,  37,  88,  81,  34,  20,  29,   6,  83,\n",
       "         2,  30,  31,   1,  32,  11,  68,  76, 106,   0,  13,  44,   4,\n",
       "        22,  80,  59,  35,  55,  91,  36,   9, 102,  63,  82,   5, 100,\n",
       "        67,  71,  72,  53,  92,  73,  70,  14,  15,  85,   3,  28,  95,\n",
       "        10,  99,  43,  19,  75,   7,  54,  96,  60,  46,  21,  69,  48,\n",
       "        17,  52,  24,  62,  57,  89,  16, 101,   8,  94,  27,  84,  23,\n",
       "        66, 104,  86,  51, 108,  97,  58])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.cluster_hdbscan.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cluster = len(y_hdbscan.unique().tolist())\n",
    "rf = RandomForestClassifier(n_estimators=n_cluster, random_state=42, min_samples_split=20)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred_rf))\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_rf)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_full = rf.predict(x_full)\n",
    "coherencia = np.mean(y_pred_full == y_hdbscan)\n",
    "print(f\"Coherencia: {coherencia * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df.copy(deep = True)\n",
    "df_final['cluster_RF'] = y_pred_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.to_csv('../../Samples/Clean/Final/STARTSOutput.csv', index=False)\n",
    "dump(rf, open(\"../../Models/RF_Q.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
